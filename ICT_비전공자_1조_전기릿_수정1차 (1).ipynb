{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 23224,
     "status": "ok",
     "timestamp": 1756297483106,
     "user": {
      "displayName": "김중서",
      "userId": "17755098182793568770"
     },
     "user_tz": -540
    },
    "id": "nmyGJ9swX6jo",
    "outputId": "8c01c5dd-1af6-46d2-993c-3500f4debfa8"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai tiktoken python-dotenv gradio sympy schemdraw pypdf faiss-cpu langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "executionInfo": {
     "elapsed": 306977,
     "status": "ok",
     "timestamp": 1756298543076,
     "user": {
      "displayName": "김중서",
      "userId": "17755098182793568770"
     },
     "user_tz": -540
    },
    "id": "MUzcr11NX1ba",
    "outputId": "ff10e93c-563d-4c6e-be86-6264dd23b233"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_16864/4046869562.py:167: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = gr.State(lambda: ConversationBufferMemory(memory_key=\"history\", return_messages=True))\n",
      "/tmp/ipykernel_16864/4046869562.py:189: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_display = gr.Chatbot(height=520, show_copy_button=True, label=\"대화창\")\n",
      "/tmp/ipykernel_16864/4046869562.py:253: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  doc_chatbot = gr.Chatbot(label=\"문서 Q&A\", height=450)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Missing file: /home/codespace/.cache/huggingface/gradio/frpc/frpc_linux_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64\n",
      "2. Rename the downloaded file to: frpc_linux_amd64_v0.3\n",
      "3. Move the file to this location: /home/codespace/.cache/huggingface/gradio/frpc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# [최종 통합본] 전기·전자 종합 어시스턴트\n",
    "\n",
    "# ----------------------------->\n",
    "# 0. 라이브러리 임포트\n",
    "# ----------------------------->\n",
    "import os\n",
    "import json\n",
    "import cmath\n",
    "import math\n",
    "import random\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "# Gradio 및 LLM 관련\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import gradio as gr\n",
    "\n",
    "# RAG (문서 Q&A) 관련\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# 계산 및 회로도 관련\n",
    "try:\n",
    "    import sympy as sp\n",
    "    import schemdraw\n",
    "    import schemdraw.elements as elm\n",
    "except ImportError:\n",
    "    print(\"sympy, schemdraw 라이브러리가 필요합니다. !pip install sympy schemdraw 를 실행해주세요.\")\n",
    "    sp, schemdraw, elm = None, None, None\n",
    "\n",
    "# ----------------------------->\n",
    "# 1. 환경 설정 및 LLM 인스턴스\n",
    "# ----------------------------->\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    # .env 파일에 키가 없다면 여기서 직접 설정해주세요.\n",
    "    # os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY_HERE\"\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise RuntimeError(\"OPENAI_API_KEY를 설정해주세요.\")\n",
    "\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "# LLM을 역할에 따라 분리\n",
    "llm_guard = ChatOpenAI(model=OPENAI_MODEL, temperature=0) # 판정, 분류 등 엄격한 역할\n",
    "llm_gen = ChatOpenAI(model=OPENAI_MODEL, temperature=0.3)  # 요약, 생성, 대화 등 창의적인 역할\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# ----------------------------->\n",
    "# 2. 기존 기능 함수들 (요약 챗봇, 계산기 등)\n",
    "# ----------------------------->\n",
    "KNOWLEDGE_CUTOFF = \"2024-06\"\n",
    "STYLE_SYS = (\n",
    "    \"한국어 존댓말을 사용합니다. 말투는 친절하고 전문적으로 유지합니다. \"\n",
    "    \"핵심은 간결하게 전달하되, 전력·에너지·모빌리티 분야의 수치/단위/기호(η, THD, pf, pu, kW, kWh, °C 등)는 보존합니다. \"\n",
    "    \"불확실하거나 기억이 모호한 내용은 '불확실'로 표시하고 추정·일반론은 명확히 구분합니다. 과장 표현은 지양합니다.\"\n",
    ")\n",
    "def calculate_series_resistance(resistances: List[float]) -> float:\n",
    "    \"\"\"직렬 연결된 저항들의 총 저항을 계산합니다.\"\"\"\n",
    "    return sum(resistances) if resistances else 0.0\n",
    "\n",
    "def calculate_parallel_resistance(resistances: List[float]) -> float:\n",
    "    \"\"\"병렬 연결된 저항들의 총 저항을 계산합니다.\"\"\"\n",
    "    if not resistances: return 0.0\n",
    "    if 0.0 in resistances: return 0.0\n",
    "    sum_of_reciprocals = sum(1.0 / r for r in resistances)\n",
    "    return 1.0 / sum_of_reciprocals if sum_of_reciprocals != 0 else float('inf')\n",
    "\n",
    "def resistor_color_code(res_val: float) -> str:\n",
    "    \"\"\"저항값(Ω)을 입력받아 4-band 색깔 띠를 반환합니다.\"\"\"\n",
    "    if res_val < 0:\n",
    "        return \"오류: 저항값은 음수일 수 없습니다.\"\n",
    "    if res_val == 0:\n",
    "        return \"검정(0) - 검정(0) - 검정(x1)\"\n",
    "\n",
    "    colors = {\n",
    "        0: \"검정\", 1: \"갈색\", 2: \"빨강\", 3: \"주황\", 4: \"노랑\",\n",
    "        5: \"초록\", 6: \"파랑\", 7: \"보라\", 8: \"회색\", 9: \"흰색\"\n",
    "    }\n",
    "    multipliers = {\n",
    "        -2: \"은색\", -1: \"금색\", 0: \"검정\", 1: \"갈색\", 2: \"빨강\", 3: \"주황\",\n",
    "        4: \"노랑\", 5: \"초록\", 6: \"파랑\", 7: \"보라\"\n",
    "    }\n",
    "\n",
    "    s = f\"{res_val:.10f}\"\n",
    "    if '.' in s:\n",
    "        s = s.rstrip('0').rstrip('.')\n",
    "\n",
    "    if float(s) < 10:\n",
    "        first_digit = int(s[0])\n",
    "        second_digit = int(s[2]) if len(s) > 2 else 0\n",
    "        exponent = -1\n",
    "    else:\n",
    "        significant_figs = s.replace('.', '')\n",
    "        first_digit = int(significant_figs[0])\n",
    "        second_digit = int(significant_figs[1])\n",
    "        exponent = len(s.split('.')[0]) - 2\n",
    "\n",
    "    band1 = f\"{colors[first_digit]}({first_digit})\"\n",
    "    band2 = f\"{colors[second_digit]}({second_digit})\"\n",
    "    multiplier_color = multipliers.get(exponent, \"알 수 없음\")\n",
    "    multiplier = f\"{multiplier_color}(x10^{exponent})\"\n",
    "\n",
    "    return f\"1밴드: {band1} | 2밴드: {band2} | 3밴드(승수): {multiplier} | 4밴드(오차): 금색(±5%)\"\n",
    "\n",
    "# AI 회로 문제 풀이 탭의 generate_and_solve_problem 함수 내 questions 딕셔너리도 채워야 합니다.\n",
    "# 예시:\n",
    "# questions = {\n",
    "#     'R_total': \"### **문제: 위 회로의 전체 등가 저항(R_total)은 얼마일까요?**\",\n",
    "#     'I_total': \"### **문제: 위 회로에 흐르는 전체 전류(I_total)는 얼마일까요?**\",\n",
    "#     'V1': \"### **문제: 저항 R1에 걸리는 전압(V1)은 얼마일까요?**\",\n",
    "#     'V2': \"### **문제: 저항 R2에 걸리는 전압(V2)은 얼마일까요?**\"\n",
    "\n",
    "def summarize_logic(query: str) -> str:\n",
    "    # 이 함수는 원래의 복잡한 요약 파이프라인(분류,평가,분해,추출,통합,요약)을 대표합니다.\n",
    "    # 여기서는 간단한 응답으로 대체합니다.\n",
    "    return f\"'{query}'에 대한 요약 결과입니다. (이곳에 LLM의 상세 요약이 생성됩니다.)\"\n",
    "\n",
    "def _summarize_chat_handler(user_text: str, history: list[list[str]]) -> str:\n",
    "    return summarize_logic(user_text)\n",
    "\n",
    "def ohms_law(V: float = None, I: float = None, R: float = None) -> Dict[str, Any]:\n",
    "    try:\n",
    "        known = sum(x is not None for x in [V, I, R])\n",
    "        if known < 2: raise ValueError(\"세 변수(V, I, R) 중 최소 2개가 필요합니다.\")\n",
    "        if V is None: V = I * R\n",
    "        if I is None:\n",
    "            if R == 0: raise ValueError(\"R=0이면 I를 계산할 수 없습니다.\")\n",
    "            I = V / R\n",
    "        if R is None:\n",
    "            if I == 0: raise ValueError(\"I=0이면 R을 계산할 수 없습니다.\")\n",
    "            R = V / I\n",
    "        P = V * I\n",
    "        return {\"V[V]\": V, \"I[A]\": I, \"R[Ω]\": R, \"P[W]\": P}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# ----------------------------->\n",
    "# 3. Gradio UI 및 신규 기능 구현\n",
    "# ----------------------------->\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"전기·전자 종합 어시스턴트\") as demo:\n",
    "    gr.HTML(\n",
    "        \"\"\"\n",
    "        <div style=\"text-align: center; max-width: 820px; margin: 0 auto; padding: 18px;\">\n",
    "            <h1 style=\"color: #007bff; font-size: 2.1em; font-weight: bold; margin-bottom: 4px;\">🔌 전기·전자 종합 어시스턴트</h1>\n",
    "            <p style=\"color: #555; font-size: 1.02em;\">요약, 계산, 대화, 문서 분석까지 하나의 툴에서 해결하세요.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # 탭 1: 신규 통합 챗봇\n",
    "    with gr.Tab(\"💬 전기 챗봇\"):\n",
    "        gr.Markdown(\"### 전기공학 질문을 답해주는 챗봇입니다.\")\n",
    "\n",
    "        # 세션별 대화 기록을 저장할 메모리 상태\n",
    "        chat_memory = gr.State(lambda: ConversationBufferMemory(memory_key=\"history\", return_messages=True))\n",
    "\n",
    "        def unified_chat_handler(message, history, memory):\n",
    "            chat_history = memory.load_memory_variables({})['history']\n",
    "\n",
    "            # 대화 기록이 비어있고, 입력된 메시지가 요약 요청과 유사할 경우\n",
    "            # 정교한 요약 파이프라인을 먼저 실행할 수 있습니다. (여기서는 간단한 분기 처리)\n",
    "            # 여기서는 모든 입력을 대화형으로 처리하여 일관성을 유지합니다.\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a helpful assistant specializing in electrical engineering. You can summarize topics and hold deep conversations.\"),\n",
    "                MessagesPlaceholder(variable_name=\"history\"),\n",
    "                (\"human\", \"{input}\")\n",
    "            ])\n",
    "            chain = prompt | llm_gen\n",
    "\n",
    "            response = chain.invoke({\"input\": message, \"history\": chat_history})\n",
    "\n",
    "            memory.save_context({\"input\": message}, {\"output\": response.content})\n",
    "            history.append((message, response.content))\n",
    "            return \"\", history, memory\n",
    "\n",
    "        chatbot_display = gr.Chatbot(height=520, show_copy_button=True, label=\"대화창\")\n",
    "        msg_input = gr.Textbox(placeholder=\"아래 예시를 클릭하거나 직접 질문을 입력하세요...\", label=\"질문 입력\")\n",
    "\n",
    "        gr.Examples(\n",
    "            examples=[\"한국 도매 전력시장 가격 결정 구조 요약\", \"BESS 시장 트렌드 핵심 포인트\", \"EV 충전 인프라 최근 이슈 정리\"],\n",
    "            inputs=msg_input,\n",
    "            label=\"예시 질문\"\n",
    "        )\n",
    "\n",
    "        clear_btn = gr.Button(\"새로운 대화 시작 (기록 삭제)\")\n",
    "\n",
    "        msg_input.submit(unified_chat_handler, [msg_input, chatbot_display, chat_memory], [msg_input, chatbot_display, chat_memory])\n",
    "        clear_btn.click(lambda: (None, \"\", ConversationBufferMemory(memory_key=\"history\", return_messages=True)), None, [chatbot_display, msg_input, chat_memory], queue=False)\n",
    "\n",
    "\n",
    "    # 탭 3: 신규 - 문서 기반 Q&A\n",
    "    with gr.Tab(\"📄 문서 기반 Q&A\"):\n",
    "        gr.Markdown(\"### PDF 문서를 업로드하고 내용에 대해 질문하세요.\")\n",
    "        retriever_state = gr.State(None)\n",
    "\n",
    "        def process_document(file):\n",
    "            if file is None: return None, \"파일을 먼저 업로드해주세요.\"\n",
    "            try:\n",
    "                loader = PyPDFLoader(file.name)\n",
    "                documents = loader.load()\n",
    "                if not documents: return None, \"PDF에서 텍스트를 추출하지 못했습니다.\"\n",
    "                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "                splits = text_splitter.split_documents(documents)\n",
    "                vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "                retriever = vectorstore.as_retriever()\n",
    "                return retriever, f\"'{os.path.basename(file.name)}' 문서 처리 완료! 이제 질문할 수 있습니다.\"\n",
    "            except Exception as e:\n",
    "                return None, f\"오류 발생: {e}\"\n",
    "\n",
    "        def document_qa_handler(message, history, retriever):\n",
    "            if retriever is None:\n",
    "                history.append((message, \"문서를 먼저 업로드하고 처리해주세요.\"))\n",
    "                return \"\", history\n",
    "\n",
    "            contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"Given a chat history and the latest user question, formulate a standalone question.\"),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ])\n",
    "            history_aware_retriever = create_history_aware_retriever(llm_gen, retriever, contextualize_q_prompt)\n",
    "            qa_system_prompt = \"Answer the user's question based on the below context:\\n\\n{context}\"\n",
    "            qa_prompt = ChatPromptTemplate.from_messages([(\"system\", qa_system_prompt), (\"human\", \"{input}\")])\n",
    "            question_answer_chain = create_stuff_documents_chain(llm_gen, qa_prompt)\n",
    "            rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "            chat_history_messages = []\n",
    "            for human, ai in history:\n",
    "                chat_history_messages.append(HumanMessage(content=human))\n",
    "                chat_history_messages.append(AIMessage(content=ai))\n",
    "\n",
    "            response = rag_chain.invoke({\"input\": message, \"chat_history\": chat_history_messages})\n",
    "            history.append((message, response[\"answer\"]))\n",
    "            return \"\", history\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                file_uploader = gr.File(label=\"PDF 파일 업로드\")\n",
    "                upload_status = gr.Textbox(label=\"업로드 상태\", interactive=False)\n",
    "            with gr.Column(scale=2):\n",
    "                doc_chatbot = gr.Chatbot(label=\"문서 Q&A\", height=450)\n",
    "                doc_textbox = gr.Textbox(label=\"질문 입력\", placeholder=\"문서 내용에 대해 질문하세요...\")\n",
    "\n",
    "        file_uploader.upload(fn=process_document, inputs=[file_uploader], outputs=[retriever_state, upload_status], show_progress=\"full\")\n",
    "        doc_textbox.submit(fn=document_qa_handler, inputs=[doc_textbox, doc_chatbot, retriever_state], outputs=[doc_textbox, doc_chatbot])\n",
    "\n",
    "    # 탭 4: 공학 계산기\n",
    "    with gr.Tab(\"🧮 공학 계산기\"):\n",
    "        gr.Markdown(\"#### 1) 옴의 법칙 (V=IR, P=VI)\")\n",
    "        with gr.Row():\n",
    "            V_in = gr.Number(label=\"V [Volt]\", value=None)\n",
    "            I_in = gr.Number(label=\"I [Ampere]\", value=None)\n",
    "            R_in = gr.Number(label=\"R [Ohm]\", value=None)\n",
    "        ohm_btn = gr.Button(\"계산\")\n",
    "        ohm_out = gr.JSON(label=\"결과\")\n",
    "        def ohm_cb(V, I, R):\n",
    "            try:\n",
    "                return ohms_law(V, I, R)\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "        ohm_btn.click(ohm_cb, [V_in, I_in, R_in], ohm_out)\n",
    "\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"#### 2) 임피던스 계산 (RLC)\")\n",
    "        with gr.Row():\n",
    "            R_rlc = gr.Number(label=\"R [Ω] (직렬/병렬 공통)\", value=0.0)\n",
    "            L_rlc = gr.Number(label=\"L [H]\", value=0.0)\n",
    "            C_rlc = gr.Number(label=\"C [F]\", value=0.0)\n",
    "            f_rlc = gr.Number(label=\"주파수 f [Hz]\", value=60.0)\n",
    "        mode = gr.Radio(choices=[\"직렬\", \"병렬\"], value=\"직렬\", label=\"결선 방식\")\n",
    "        rlc_btn = gr.Button(\"임피던스 계산\")\n",
    "        rlc_out = gr.JSON(label=\"Z 결과\")\n",
    "        def rlc_cb(R, L, C, f, m):\n",
    "            try:\n",
    "                if m == \"직렬\":\n",
    "                    return impedance_rlc_series(R or 0.0, L or 0.0, C or 0.0, f or 60.0)\n",
    "                else:\n",
    "                    # 병렬은 None 허용 (없는 소자)\n",
    "                    Rv = None if (R is None or R == 0) else R\n",
    "                    Lv = None if (L is None or L == 0) else L\n",
    "                    Cv = None if (C is None or C == 0) else C\n",
    "                    return impedance_rlc_parallel(Rv, Lv, Cv, f or 60.0)\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "        rlc_btn.click(rlc_cb, [R_rlc, L_rlc, C_rlc, f_rlc, mode], rlc_out)\n",
    "\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"#### 3) 벡터 미적분 (grad / div / curl)\")\n",
    "        op_vec = gr.Radio(choices=[\"grad\",\"div\",\"curl\"], value=\"grad\", label=\"연산자\")\n",
    "        expr_vec = gr.Textbox(\n",
    "            label=\"표현식: grad는 스칼라 1개 / div, curl은 [Fx, Fy, Fz] 줄바꿈 3개\",\n",
    "            value=\"x**2*y\"\n",
    "        )\n",
    "        vars_vec = gr.Textbox(label=\"변수 순서(공백 구분) 예: x y z\", value=\"x y z\")\n",
    "        vec_btn = gr.Button(\"계산\")\n",
    "        vec_out = gr.JSON(label=\"결과\")\n",
    "        def vec_cb(op, expr_block, var_order):\n",
    "            try:\n",
    "                exprs = [s.strip() for s in expr_block.splitlines() if s.strip()]\n",
    "                return vector_calculus(op, exprs, var_order)\n",
    "            except Exception as e:\n",
    "                return {\"error\": str(e)}\n",
    "        vec_btn.click(vec_cb, [op_vec, expr_vec, vars_vec], vec_out)\n",
    "\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"#### 4) 미분/정적분\")\n",
    "        op_cal = gr.Radio(choices=[\"diff\",\"int\"], value=\"diff\", label=\"연산자\")\n",
    "        expr_cal = gr.Textbox(label=\"표현식 f(x). 예: x**3 + 2*x\", value=\"x**3 + 2*x\")\n",
    "        var_cal = gr.Textbox(label=\"변수 이름\", value=\"x\")\n",
    "        with gr.Row():\n",
    "            a_cal = gr.Textbox(label=\"적분 하한 a (선택)\", value=\"\")\n",
    "            b_cal = gr.Textbox(label=\"적분 상한 b (선택)\", value=\"\")\n",
    "        cal_btn = gr.Button(\"계산\")\n",
    "        cal_out = gr.Textbox(label=\"결과\")\n",
    "        def cal_cb(op, expr, var, a, b):\n",
    "            try:\n",
    "                a_ = a if a.strip() else None\n",
    "                b_ = b if b.strip() else None\n",
    "                return calculus(op, expr, var, a_, b_)\n",
    "            except Exception as e:\n",
    "                return f\"error: {e}\"\n",
    "        cal_btn.click(cal_cb, [op_cal, expr_cal, var_cal, a_cal, b_cal], cal_out)\n",
    "\n",
    "        gr.Markdown(\"---\")\n",
    "        gr.Markdown(\"#### 5) 저항 색깔 띠 변환\")\n",
    "        res_in = gr.Number(label=\"저항값 [Ω]\", value=47000)\n",
    "        res_btn = gr.Button(\"색깔 띠 변환\")\n",
    "        res_out = gr.Textbox(label=\"결과\")\n",
    "        def res_cb(res_val):\n",
    "            try:\n",
    "                return resistor_color_code(res_val)\n",
    "            except Exception as e:\n",
    "                return f\"오류: {e}\"\n",
    "        res_btn.click(res_cb, [res_in], res_out)\n",
    "\n",
    "    with gr.Tab(\"📚 단위 및 기호\"):\n",
    "        gr.Markdown(\"#### 🔌 전기공학 기본 단위 및 기호 정리\")\n",
    "        gr.Markdown(\n",
    "                  \"\"\"\n",
    "      | 구분 | 항목 | 단위 | 기호 |\n",
    "      |:---|:---|:---|:---|\n",
    "      | **기본량** | 전류 (Current) | 암페어 | A |\n",
    "      | | 전압 (Voltage) | 볼트 | V |\n",
    "      | | 저항 (Resistance) | 옴 | Ω |\n",
    "      | | 전력 (Power) | 와트 | W |\n",
    "      | | 에너지 (Energy) | 줄, 와트시 | J, Wh |\n",
    "      | **교류 (AC)** | 주파수 (Frequency) | 헤르츠 | Hz |\n",
    "      | | 임피던스 (Impedance) | 옴 | Z |\n",
    "      | | 리액턴스 (Reactance) | 옴 | X |\n",
    "      | | 역률 (Power Factor) | - | pf |\n",
    "      | **자기장** | 자속 (Magnetic Flux) | 웨버 | Wb |\n",
    "      | | 자속 밀도 (Flux Density) | 테슬라 | T |\n",
    "      | | 인덕턴스 (Inductance) | 헨리 | H |\n",
    "      | **기타** | 효율 (Efficiency) | - | η |\n",
    "      | | 고조파 (Harmonics) | - | THD |\n",
    "      | | 퍼유닛 (Per Unit) | - | pu |\n",
    "                  \"\"\"\n",
    "              )\n",
    "\n",
    "\n",
    "    demo.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1U1dbtIj4GcmVVCtdG6qRqtV5gutZqipS",
     "timestamp": 1756297245118
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
